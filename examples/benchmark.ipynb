{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install -e .. datasets sympy numpy matplotlib seaborn -q  # Install dev version of smolagents + some packages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constants and utilities/tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Benchmark date\n",
    "# - set a concrete date:\n",
    "DATE = \"2024-12-26\"\n",
    "# - or use default: today\n",
    "# DATE = None\n",
    "\n",
    "# Evaluation dataset\n",
    "# - the dataset is gated, so you must first visit its page to request access: https://huggingface.co/datasets/smolagents-benchmark/benchmark-v1\n",
    "EVAL_DATASET = \"smolagents/benchmark-v1\"\n",
    "\n",
    "# Answers dataset: it must be a gated dataset; required to score the answers\n",
    "ANSWERS_DATASET = \"smolagents/answers\"\n",
    "# Whether to push the answers dataset to the Hub\n",
    "PUSH_ANSWERS_DATASET_TO_HUB = True\n",
    "\n",
    "# Results dataset\n",
    "RESULTS_DATASET = \"smolagents/results\"\n",
    "# Whether to push the results dataset to the Hub\n",
    "PUSH_RESULTS_DATASET_TO_HUB = True\n",
    "\n",
    "\n",
    "import datetime\n",
    "import json\n",
    "import os\n",
    "import re\n",
    "import string\n",
    "import time\n",
    "import warnings\n",
    "from typing import List\n",
    "\n",
    "import datasets\n",
    "from dotenv import load_dotenv\n",
    "from tqdm import tqdm\n",
    "\n",
    "from smolagents import (\n",
    "    AgentError,\n",
    "    CodeAgent,\n",
    "    GoogleSearchTool,\n",
    "    HfApiModel,\n",
    "    PythonInterpreterTool,\n",
    "    ToolCallingAgent,\n",
    "    VisitWebpageTool,\n",
    ")\n",
    "from smolagents.agents import ActionStep\n",
    "\n",
    "\n",
    "load_dotenv()\n",
    "os.makedirs(\"output\", exist_ok=True)\n",
    "\n",
    "\n",
    "def serialize_agent_error(obj):\n",
    "    if isinstance(obj, AgentError):\n",
    "        return {\"error_type\": obj.__class__.__name__, \"message\": obj.message}\n",
    "    else:\n",
    "        return str(obj)\n",
    "\n",
    "\n",
    "def answer_questions(\n",
    "    eval_ds,\n",
    "    agent,\n",
    "    model_id,\n",
    "    action_type,\n",
    "    is_vanilla_llm=False,\n",
    "    date=DATE,\n",
    "    output_dir=\"output\",\n",
    "    push_to_hub_dataset=ANSWERS_DATASET if PUSH_ANSWERS_DATASET_TO_HUB else None,\n",
    "):\n",
    "    date = date or datetime.date.today().isoformat()\n",
    "\n",
    "    for task in eval_ds:\n",
    "        file_name = f\"output/{model_id.replace('/', '__')}__{action_type}__{task}__{date}.jsonl\"\n",
    "        answered_questions = []\n",
    "        if os.path.exists(file_name):\n",
    "            with open(file_name, \"r\") as f:\n",
    "                for line in f:\n",
    "                    answered_questions.append(json.loads(line)[\"question\"])\n",
    "\n",
    "        for _, example in tqdm(enumerate(eval_ds[task]), total=len(eval_ds[task])):\n",
    "            try:\n",
    "                question = example[\"question\"]\n",
    "                if example[\"source\"] == \"SimpleQA\":\n",
    "                    question += \" Answer with only the final number.\"\n",
    "                if example[\"source\"] == \"MATH\":\n",
    "                    question += \" Write code, not latex.\"\n",
    "                if question in answered_questions:\n",
    "                    continue\n",
    "                start_time = time.time()\n",
    "\n",
    "                if is_vanilla_llm:\n",
    "                    llm = agent\n",
    "                    answer = str(llm([{\"role\": \"user\", \"content\": question}]).content)\n",
    "                    token_count = {\n",
    "                        \"input\": llm.last_input_token_count,\n",
    "                        \"output\": llm.last_output_token_count,\n",
    "                    }\n",
    "                    intermediate_steps = str([])\n",
    "                else:\n",
    "                    answer = str(agent.run(question))\n",
    "                    token_count = agent.monitor.get_total_token_counts()\n",
    "                    intermediate_steps = str(agent.logs)\n",
    "                    # Remove memory from logs to make them more compact.\n",
    "                    for step in agent.logs:\n",
    "                        if isinstance(step, ActionStep):\n",
    "                            step.agent_memory = None\n",
    "\n",
    "                end_time = time.time()\n",
    "                annotated_example = {\n",
    "                    \"model_id\": model_id,\n",
    "                    \"agent_action_type\": action_type,\n",
    "                    \"question\": question,\n",
    "                    \"answer\": answer,\n",
    "                    \"true_answer\": example[\"true_answer\"],\n",
    "                    \"source\": example[\"source\"],\n",
    "                    \"intermediate_steps\": intermediate_steps,\n",
    "                    \"start_time\": start_time,\n",
    "                    \"end_time\": end_time,\n",
    "                    \"token_counts\": token_count,\n",
    "                }\n",
    "\n",
    "                with open(file_name, \"a\") as f:\n",
    "                    json.dump(annotated_example, f, default=serialize_agent_error)\n",
    "                    f.write(\"\\n\")  # add a newline for JSONL format\n",
    "            except Exception as e:\n",
    "                print(\"Failed:\", e)\n",
    "\n",
    "        if push_to_hub_dataset:\n",
    "            ds = datasets.Dataset.from_pandas(pd.read_json(file_name, lines=True), split=\"test\", preserve_index=False)\n",
    "            config = f\"{model_id.replace('/', '__')}__{action_type}__{task}\"\n",
    "            data_dir = f\"{model_id}/{action_type}/{task}/{date}\"\n",
    "            ds.push_to_hub(\n",
    "                push_to_hub_dataset,\n",
    "                config_name=config,\n",
    "                data_dir=data_dir,\n",
    "                split=\"test\",\n",
    "                commit_message=f\"Upload {config}\",\n",
    "            )\n",
    "\n",
    "\n",
    "def normalize_number_str(number_str: str) -> float:\n",
    "    # we replace these common units and commas to allow\n",
    "    # conversion to float\n",
    "    for char in [\"$\", \"%\", \",\"]:\n",
    "        number_str = number_str.replace(char, \"\")\n",
    "    try:\n",
    "        return float(number_str)\n",
    "    except ValueError:\n",
    "        return float(\"inf\")\n",
    "\n",
    "\n",
    "def split_string(\n",
    "    s: str,\n",
    "    char_list: list[str] = [\",\", \";\"],\n",
    ") -> list[str]:\n",
    "    pattern = f\"[{''.join(char_list)}]\"\n",
    "    return re.split(pattern, s)\n",
    "\n",
    "\n",
    "def is_float(element: any) -> bool:\n",
    "    try:\n",
    "        float(element)\n",
    "        return True\n",
    "    except ValueError:\n",
    "        return False\n",
    "\n",
    "\n",
    "def normalize_str(input_str, remove_punct=True) -> str:\n",
    "    \"\"\"\n",
    "    Normalize a string by:\n",
    "    - Removing all white spaces\n",
    "    - Optionally removing punctuation (if remove_punct is True)\n",
    "    - Converting to lowercase\n",
    "    Parameters:\n",
    "    - input_str: str, the string to normalize\n",
    "    - remove_punct: bool, whether to remove punctuation (default: True)\n",
    "    Returns:\n",
    "    - str, the normalized string\n",
    "    \"\"\"\n",
    "    # Remove all white spaces. Required e.g for seagull vs. sea gull\n",
    "    no_spaces = re.sub(r\"\\s\", \"\", input_str)\n",
    "\n",
    "    # Remove punctuation, if specified.\n",
    "    if remove_punct:\n",
    "        translator = str.maketrans(\"\", \"\", string.punctuation)\n",
    "        return no_spaces.lower().translate(translator)\n",
    "    else:\n",
    "        return no_spaces.lower()\n",
    "\n",
    "\n",
    "def extract_numbers(text: str) -> List[str]:\n",
    "    \"\"\"This pattern matches:\n",
    "    - Optional negative sign\n",
    "    - Numbers with optional comma thousand separators\n",
    "    - Optional decimal points with decimal numbers\n",
    "    \"\"\"\n",
    "    pattern = r\"-?(?:\\d{1,3}(?:,\\d{3})+|\\d+)(?:\\.\\d+)?\"\n",
    "\n",
    "    return [el.replace(\",\", \"\") for el in re.findall(pattern, text)]\n",
    "\n",
    "\n",
    "def get_question_score_gaia(\n",
    "    model_answer: str,\n",
    "    ground_truth: str,\n",
    ") -> bool:\n",
    "    \"\"\"Scoring function used to score functions from the GAIA benchmark\"\"\"\n",
    "    if is_float(ground_truth):\n",
    "        normalized_answer = normalize_number_str(str(model_answer))\n",
    "        return normalized_answer == float(ground_truth)\n",
    "\n",
    "    elif any(char in ground_truth for char in [\",\", \";\"]):  # if gt is a list\n",
    "        # question with the fish: normalization removes punct\n",
    "        gt_elems = split_string(ground_truth)\n",
    "        ma_elems = split_string(model_answer)\n",
    "\n",
    "        if len(gt_elems) != len(ma_elems):  # check length is the same\n",
    "            warnings.warn(\"Answer lists have different lengths, returning False.\", UserWarning)\n",
    "            return False\n",
    "\n",
    "        comparisons = []\n",
    "        for ma_elem, gt_elem in zip(ma_elems, gt_elems):  # compare each element as float or str\n",
    "            if is_float(gt_elem):\n",
    "                normalized_ma_elem = normalize_number_str(ma_elem)\n",
    "                comparisons.append(normalized_ma_elem == float(gt_elem))\n",
    "            else:\n",
    "                # we do not remove punct since comparisons can include punct\n",
    "                comparisons.append(\n",
    "                    normalize_str(ma_elem, remove_punct=False) == normalize_str(gt_elem, remove_punct=False)\n",
    "                )\n",
    "        return all(comparisons)\n",
    "\n",
    "    else:  # if gt is a str\n",
    "        return normalize_str(model_answer) == normalize_str(ground_truth)\n",
    "\n",
    "\n",
    "def get_correct(row):\n",
    "    if row[\"source\"] == \"MATH\":  # Checks the last number in answer\n",
    "        numbers_answer = extract_numbers(str(row[\"answer\"]))\n",
    "        if len(numbers_answer) == 0:\n",
    "            return False\n",
    "        return float(numbers_answer[-1]) == float(row[\"true_answer\"])\n",
    "    else:\n",
    "        return get_question_score_gaia(str(row[\"answer\"]), str(row[\"true_answer\"]))\n",
    "\n",
    "\n",
    "def score_answers(\n",
    "    answers_subsets,\n",
    "    answers_dataset=ANSWERS_DATASET,\n",
    "    date=DATE,\n",
    "    push_to_hub_dataset=RESULTS_DATASET if PUSH_RESULTS_DATASET_TO_HUB else None,\n",
    "    set_default=True,\n",
    "):\n",
    "    if not answers_dataset:\n",
    "        raise ValueError(\"Pass 'answers_dataset' to load the answers from it\")\n",
    "    date = date or datetime.date.today().isoformat()\n",
    "    results = []\n",
    "    for answers_subset in answers_subsets:\n",
    "        *model_id, action_type, task = answers_subset.split(\"__\")\n",
    "        model_id = \"/\".join(model_id)\n",
    "        ds = datasets.load_dataset(answers_dataset, answers_subset, split=\"test\")\n",
    "        df = ds.to_pandas()\n",
    "        df[\"correct\"] = df.apply(get_correct, axis=1)\n",
    "        acc = df[\"correct\"].mean().item()\n",
    "        result = df.loc[0, [\"model_id\", \"agent_action_type\", \"source\"]].to_dict()\n",
    "        result[\"acc\"] = acc\n",
    "        results.append(result)\n",
    "    df = pd.DataFrame(results)\n",
    "    df[\"agent_action_type\"] = df[\"agent_action_type\"].str.replace(\"tool_calling\", \"tool-calling\")\n",
    "\n",
    "    if push_to_hub_dataset:\n",
    "        ds = datasets.Dataset.from_pandas(df)\n",
    "        config = date\n",
    "        set_default = set_default\n",
    "        ds.push_to_hub(\n",
    "            push_to_hub_dataset, config_name=config, set_default=set_default, commit_message=f\"Upload {config} results\"\n",
    "        )\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['gaia', 'math', 'simpleqa']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>source</th>\n",
       "      <th>true_answer</th>\n",
       "      <th>true_reasoning</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What year was the municipality of Ramiriquí, B...</td>\n",
       "      <td>SimpleQA</td>\n",
       "      <td>1541</td>\n",
       "      <td>['https://en.wikipedia.org/wiki/Ramiriqu%C3%AD...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>In what year did Hjalmar Hvam invent a mechani...</td>\n",
       "      <td>SimpleQA</td>\n",
       "      <td>1937</td>\n",
       "      <td>['https://www.kgw.com/article/features/portlan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>In which year did Fayaz A. Malik (an Indian ph...</td>\n",
       "      <td>SimpleQA</td>\n",
       "      <td>2009</td>\n",
       "      <td>['https://en.wikipedia.org/wiki/Fayaz_A._Malik...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>In which year was John B. Goodenough elected a...</td>\n",
       "      <td>SimpleQA</td>\n",
       "      <td>2010</td>\n",
       "      <td>['https://en.wikipedia.org/wiki/John_B._Gooden...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>In which year did Atul Gawande earn an M.A. in...</td>\n",
       "      <td>SimpleQA</td>\n",
       "      <td>1989</td>\n",
       "      <td>['https://en.wikipedia.org/wiki/Atul_Gawande',...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            question    source true_answer  \\\n",
       "0  What year was the municipality of Ramiriquí, B...  SimpleQA        1541   \n",
       "1  In what year did Hjalmar Hvam invent a mechani...  SimpleQA        1937   \n",
       "2  In which year did Fayaz A. Malik (an Indian ph...  SimpleQA        2009   \n",
       "3  In which year was John B. Goodenough elected a...  SimpleQA        2010   \n",
       "4  In which year did Atul Gawande earn an M.A. in...  SimpleQA        1989   \n",
       "\n",
       "                                      true_reasoning  \n",
       "0  ['https://en.wikipedia.org/wiki/Ramiriqu%C3%AD...  \n",
       "1  ['https://www.kgw.com/article/features/portlan...  \n",
       "2  ['https://en.wikipedia.org/wiki/Fayaz_A._Malik...  \n",
       "3  ['https://en.wikipedia.org/wiki/John_B._Gooden...  \n",
       "4  ['https://en.wikipedia.org/wiki/Atul_Gawande',...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "# Choose the tasks to evaluate on:\n",
    "# tasks = [\"gaia\"]\n",
    "# or evaluate on all tasks: [\"gaia\", \"math\", \"simpleqa\"]\n",
    "tasks = datasets.get_dataset_config_names(EVAL_DATASET)\n",
    "print(tasks)\n",
    "\n",
    "\n",
    "eval_ds = {task: datasets.load_dataset(EVAL_DATASET, task, split=\"test\") for task in tasks}\n",
    "pd.DataFrame(eval_ds[\"simpleqa\"]).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Benchmark agents\n",
    "\n",
    "### Open models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "open_model_ids = [\n",
    "    \"meta-llama/Llama-3.3-70B-Instruct\",\n",
    "    # \"Qwen/QwQ-32B-Preview\",\n",
    "    \"Qwen/Qwen2.5-72B-Instruct\",\n",
    "    \"Qwen/Qwen2.5-Coder-32B-Instruct\",\n",
    "    \"meta-llama/Llama-3.2-3B-Instruct\",\n",
    "    \"meta-llama/Llama-3.1-8B-Instruct\",\n",
    "    \"mistralai/Mistral-Nemo-Instruct-2407\",\n",
    "    # \"HuggingFaceTB/SmolLM2-1.7B-Instruct\",\n",
    "    # \"meta-llama/Llama-3.1-70B-Instruct\",\n",
    "]\n",
    "\n",
    "\n",
    "for model_id in open_model_ids:\n",
    "    print(f\"Evaluating '{model_id}'...\")\n",
    "    # action_type = \"tool-calling\"\n",
    "    # agent = ToolCallingAgent(\n",
    "    #     tools=[GoogleSearchTool(), VisitWebpageTool(), PythonInterpreterTool()],\n",
    "    #     model=HfApiModel(model_id),\n",
    "    #     max_steps=10,\n",
    "    # )\n",
    "    # answer_questions(eval_ds, agent, model_id, action_type)\n",
    "\n",
    "    action_type = \"code\"\n",
    "    agent = CodeAgent(\n",
    "        tools=[GoogleSearchTool(), VisitWebpageTool()],\n",
    "        model=HfApiModel(model_id),\n",
    "        additional_authorized_imports=[\"numpy\", \"sympy\"],\n",
    "        max_steps=10,\n",
    "    )\n",
    "    answer_questions(eval_ds, agent, model_id, action_type)\n",
    "\n",
    "    # Also evaluate vanilla model\n",
    "    action_type = \"vanilla\"\n",
    "    llm = HfApiModel(model_id)\n",
    "    answer_questions(eval_ds, llm, model_id, action_type, is_vanilla_llm=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Closed models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from smolagents import LiteLLMModel\n",
    "\n",
    "\n",
    "litellm_model_ids = [\"gpt-4o\", \"anthropic/claude-3-5-sonnet-latest\"]\n",
    "\n",
    "\n",
    "for model_id in litellm_model_ids:\n",
    "    print(f\"Evaluating '{model_id}'...\")\n",
    "    action_type = \"tool-calling\"\n",
    "    agent = ToolCallingAgent(\n",
    "        tools=[\n",
    "            GoogleSearchTool(),\n",
    "            VisitWebpageTool(),\n",
    "            PythonInterpreterTool([\"numpy\", \"sympy\"]),\n",
    "        ],\n",
    "        model=LiteLLMModel(model_id),\n",
    "        max_steps=10,\n",
    "    )\n",
    "    answer_questions(eval_ds, agent, model_id, action_type)\n",
    "\n",
    "    action_type = \"code\"\n",
    "    agent = CodeAgent(\n",
    "        tools=[GoogleSearchTool(), VisitWebpageTool()],\n",
    "        model=LiteLLMModel(model_id),\n",
    "        additional_authorized_imports=[\"numpy\", \"sympy\"],\n",
    "        max_steps=10,\n",
    "    )\n",
    "    answer_questions(eval_ds, agent, model_id, action_type)\n",
    "\n",
    "    # Also evaluate vanilla model\n",
    "    action_type = \"vanilla\"\n",
    "    llm = LiteLLMModel(model_id)\n",
    "    answer_questions(eval_ds, llm, model_id, action_type, is_vanilla_llm=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import glob\n",
    "# import json\n",
    "\n",
    "# jsonl_files = glob.glob(f\"output/*.jsonl\")\n",
    "\n",
    "# for file_path in jsonl_files:\n",
    "#     if \"-Nemo-\" in file_path and \"-vanilla-\" in file_path:\n",
    "#         print(file_path)\n",
    "#         # Read all lines and filter out SimpleQA sources\n",
    "#         filtered_lines = []\n",
    "#         removed = 0\n",
    "#         with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "#             for line in f:\n",
    "#                 try:\n",
    "#                     data = json.loads(line.strip())\n",
    "#                     data[\"answer\"] = data[\"answer\"][\"content\"]\n",
    "#                     # if not any([question in data[\"question\"] for question in eval_ds[\"question\"]]):\n",
    "#                     #     removed +=1\n",
    "#                     # else:\n",
    "#                     filtered_lines.append(json.dumps(data) + \"\\n\")\n",
    "#                 except json.JSONDecodeError:\n",
    "#                     print(\"Invalid line:\", line)\n",
    "#                     continue  # Skip invalid JSON lines\n",
    "#         print(f\"Removed {removed} lines.\")\n",
    "#         # Write filtered content back to the same file\n",
    "#         with open(\n",
    "#             str(file_path).replace(\"-vanilla-\", \"-vanilla2-\"), \"w\", encoding=\"utf-8\"\n",
    "#         ) as f:\n",
    "#             f.writelines(filtered_lines)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Score answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading readme: 100%|██████████| 68.9k/68.9k [00:00<00:00, 57.3MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of answers_subsets 84\n",
      "Example of answers_subset Qwen__Qwen2.5-72B-Instruct__code__gaia\n"
     ]
    }
   ],
   "source": [
    "import datasets\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# Choose the answers subsets to score:\n",
    "# answers_subsets = [\"meta-llama__Llama-3.1-8B-Instruct__code__gaia\"]\n",
    "# or get all the answers subsets present in the ANSWERS_DATASET\n",
    "answers_subsets = datasets.get_dataset_config_names(ANSWERS_DATASET)\n",
    "print(\"Number of answers_subsets\", len(answers_subsets))\n",
    "print(\"Example of answers_subset\", answers_subsets[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading data: 100%|██████████| 2.00M/2.00M [00:00<00:00, 8.93MB/s]\n",
      "Generating test split: 100%|██████████| 32/32 [00:00<00:00, 2747.66 examples/s]\n",
      "/var/folders/6m/9b1tts6d5w960j80wbw9tx3m0000gn/T/ipykernel_7591/2098693032.py:215: UserWarning: Answer lists have different lengths, returning False.\n",
      "  warnings.warn(\"Answer lists have different lengths, returning False.\", UserWarning)\n",
      "Downloading data: 100%|██████████| 696k/696k [00:00<00:00, 3.88MB/s]\n",
      "Generating test split: 100%|██████████| 50/50 [00:00<00:00, 8330.63 examples/s]\n",
      "Downloading data: 100%|██████████| 836k/836k [00:00<00:00, 5.01MB/s]\n",
      "Generating test split: 100%|██████████| 50/50 [00:00<00:00, 6582.40 examples/s]\n",
      "Downloading data: 100%|██████████| 37.8k/37.8k [00:00<00:00, 264kB/s]\n",
      "Generating test split: 100%|██████████| 32/32 [00:00<00:00, 9176.65 examples/s]\n",
      "/var/folders/6m/9b1tts6d5w960j80wbw9tx3m0000gn/T/ipykernel_7591/2098693032.py:215: UserWarning: Answer lists have different lengths, returning False.\n",
      "  warnings.warn(\"Answer lists have different lengths, returning False.\", UserWarning)\n",
      "Downloading data: 100%|██████████| 51.8k/51.8k [00:00<00:00, 329kB/s]\n",
      "Generating test split: 100%|██████████| 50/50 [00:00<00:00, 13430.37 examples/s]\n",
      "Downloading data: 100%|██████████| 10.2k/10.2k [00:00<00:00, 62.5kB/s]\n",
      "Generating test split: 100%|██████████| 50/50 [00:00<00:00, 15019.35 examples/s]\n",
      "Downloading data: 100%|██████████| 1.71M/1.71M [00:00<00:00, 8.28MB/s]\n",
      "Generating test split: 100%|██████████| 32/32 [00:00<00:00, 2768.17 examples/s]\n",
      "/var/folders/6m/9b1tts6d5w960j80wbw9tx3m0000gn/T/ipykernel_7591/2098693032.py:215: UserWarning: Answer lists have different lengths, returning False.\n",
      "  warnings.warn(\"Answer lists have different lengths, returning False.\", UserWarning)\n",
      "Downloading data: 100%|██████████| 503k/503k [00:00<00:00, 3.10MB/s]\n",
      "Generating test split: 100%|██████████| 50/50 [00:00<00:00, 7060.88 examples/s]\n",
      "Downloading data: 100%|██████████| 1.31M/1.31M [00:00<00:00, 6.58MB/s]\n",
      "Generating test split: 100%|██████████| 50/50 [00:00<00:00, 3951.97 examples/s]\n",
      "Downloading data: 100%|██████████| 1.38M/1.38M [00:00<00:00, 7.66MB/s]\n",
      "Generating test split: 100%|██████████| 32/32 [00:00<00:00, 2145.77 examples/s]\n",
      "/var/folders/6m/9b1tts6d5w960j80wbw9tx3m0000gn/T/ipykernel_7591/2098693032.py:215: UserWarning: Answer lists have different lengths, returning False.\n",
      "  warnings.warn(\"Answer lists have different lengths, returning False.\", UserWarning)\n",
      "Downloading data: 100%|██████████| 919k/919k [00:00<00:00, 4.01MB/s]\n",
      "Generating test split: 100%|██████████| 50/50 [00:00<00:00, 3634.52 examples/s]\n",
      "Downloading data: 100%|██████████| 1.04M/1.04M [00:00<00:00, 6.19MB/s]\n",
      "Generating test split: 100%|██████████| 50/50 [00:00<00:00, 4688.57 examples/s]\n",
      "Downloading data: 100%|██████████| 36.8k/36.8k [00:00<00:00, 246kB/s]\n",
      "Generating test split: 100%|██████████| 32/32 [00:00<00:00, 8863.94 examples/s]\n",
      "/var/folders/6m/9b1tts6d5w960j80wbw9tx3m0000gn/T/ipykernel_7591/2098693032.py:215: UserWarning: Answer lists have different lengths, returning False.\n",
      "  warnings.warn(\"Answer lists have different lengths, returning False.\", UserWarning)\n",
      "Downloading data: 100%|██████████| 60.5k/60.5k [00:00<00:00, 375kB/s]\n",
      "Generating test split: 100%|██████████| 50/50 [00:00<00:00, 12088.72 examples/s]\n",
      "Downloading data: 100%|██████████| 12.1k/12.1k [00:00<00:00, 86.4kB/s]\n",
      "Generating test split: 100%|██████████| 50/50 [00:00<00:00, 12781.28 examples/s]\n",
      "Downloading data: 100%|██████████| 1.09M/1.09M [00:00<00:00, 5.48MB/s]\n",
      "Generating test split: 100%|██████████| 32/32 [00:00<00:00, 3293.93 examples/s]\n",
      "/var/folders/6m/9b1tts6d5w960j80wbw9tx3m0000gn/T/ipykernel_7591/2098693032.py:215: UserWarning: Answer lists have different lengths, returning False.\n",
      "  warnings.warn(\"Answer lists have different lengths, returning False.\", UserWarning)\n",
      "Downloading data: 100%|██████████| 321k/321k [00:00<00:00, 2.15MB/s]\n",
      "Generating test split: 100%|██████████| 50/50 [00:00<00:00, 6897.62 examples/s]\n",
      "Downloading data: 100%|██████████| 607k/607k [00:00<00:00, 2.79MB/s]\n",
      "Generating test split: 100%|██████████| 50/50 [00:00<00:00, 5973.60 examples/s]\n",
      "Downloading data: 100%|██████████| 456k/456k [00:00<00:00, 1.82MB/s]\n",
      "Generating test split: 100%|██████████| 32/32 [00:00<00:00, 3176.45 examples/s]\n",
      "/var/folders/6m/9b1tts6d5w960j80wbw9tx3m0000gn/T/ipykernel_7591/2098693032.py:215: UserWarning: Answer lists have different lengths, returning False.\n",
      "  warnings.warn(\"Answer lists have different lengths, returning False.\", UserWarning)\n",
      "Downloading data: 100%|██████████| 369k/369k [00:00<00:00, 2.25MB/s]\n",
      "Generating test split: 100%|██████████| 50/50 [00:00<00:00, 6615.20 examples/s]\n",
      "Downloading data: 100%|██████████| 500k/500k [00:00<00:00, 3.13MB/s]\n",
      "Generating test split: 100%|██████████| 50/50 [00:00<00:00, 6249.34 examples/s]\n",
      "Downloading data: 100%|██████████| 26.6k/26.6k [00:00<00:00, 199kB/s]\n",
      "Generating test split: 100%|██████████| 32/32 [00:00<00:00, 12318.07 examples/s]\n",
      "/var/folders/6m/9b1tts6d5w960j80wbw9tx3m0000gn/T/ipykernel_7591/2098693032.py:215: UserWarning: Answer lists have different lengths, returning False.\n",
      "  warnings.warn(\"Answer lists have different lengths, returning False.\", UserWarning)\n",
      "Downloading data: 100%|██████████| 45.1k/45.1k [00:00<00:00, 277kB/s]\n",
      "Generating test split: 100%|██████████| 50/50 [00:00<00:00, 10105.30 examples/s]\n",
      "Downloading data: 100%|██████████| 11.6k/11.6k [00:00<00:00, 86.4kB/s]\n",
      "Generating test split: 100%|██████████| 50/50 [00:00<00:00, 12327.49 examples/s]\n",
      "Downloading data: 100%|██████████| 1.31M/1.31M [00:00<00:00, 4.79MB/s]\n",
      "Generating test split: 100%|██████████| 32/32 [00:00<00:00, 3846.99 examples/s]\n",
      "/var/folders/6m/9b1tts6d5w960j80wbw9tx3m0000gn/T/ipykernel_7591/2098693032.py:215: UserWarning: Answer lists have different lengths, returning False.\n",
      "  warnings.warn(\"Answer lists have different lengths, returning False.\", UserWarning)\n",
      "Downloading data: 100%|██████████| 859k/859k [00:00<00:00, 4.67MB/s]\n",
      "Generating test split: 100%|██████████| 50/50 [00:00<00:00, 4221.92 examples/s]\n",
      "Downloading data: 100%|██████████| 843k/843k [00:00<00:00, 4.07MB/s]\n",
      "Generating test split: 100%|██████████| 50/50 [00:00<00:00, 4286.73 examples/s]\n",
      "Downloading data: 100%|██████████| 981k/981k [00:00<00:00, 4.12MB/s]\n",
      "Generating test split: 100%|██████████| 32/32 [00:00<00:00, 1462.40 examples/s]\n",
      "/var/folders/6m/9b1tts6d5w960j80wbw9tx3m0000gn/T/ipykernel_7591/2098693032.py:215: UserWarning: Answer lists have different lengths, returning False.\n",
      "  warnings.warn(\"Answer lists have different lengths, returning False.\", UserWarning)\n",
      "Downloading data: 100%|██████████| 904k/904k [00:00<00:00, 2.59MB/s]\n",
      "Generating test split: 100%|██████████| 50/50 [00:00<00:00, 3160.12 examples/s]\n",
      "Downloading data: 100%|██████████| 1.15M/1.15M [00:00<00:00, 5.39MB/s]\n",
      "Generating test split: 100%|██████████| 50/50 [00:00<00:00, 4320.82 examples/s]\n",
      "Generating test split:   0%|          | 0/32 [00:00<?, ? examples/s]\n"
     ]
    },
    {
     "ename": "NonMatchingSplitsSizesError",
     "evalue": "[{'expected': SplitInfo(name='test', num_bytes=4527563, num_examples=32, shard_lengths=None, dataset_name=None), 'recorded': SplitInfo(name='test', num_bytes=0, num_examples=0, shard_lengths=None, dataset_name='answers')}]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNonMatchingSplitsSizesError\u001b[0m               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m result_df \u001b[38;5;241m=\u001b[39m \u001b[43mscore_answers\u001b[49m\u001b[43m(\u001b[49m\u001b[43manswers_subsets\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m result_df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124macc\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m (result_df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124macc\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m100\u001b[39m)\u001b[38;5;241m.\u001b[39mround(\u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m      3\u001b[0m result_df\u001b[38;5;241m.\u001b[39mhead()\n",
      "Cell \u001b[0;32mIn[2], line 258\u001b[0m, in \u001b[0;36mscore_answers\u001b[0;34m(answers_subsets, answers_dataset, date, push_to_hub_dataset, set_default)\u001b[0m\n\u001b[1;32m    256\u001b[0m \u001b[38;5;241m*\u001b[39mmodel_id, action_type, task \u001b[38;5;241m=\u001b[39m answers_subset\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    257\u001b[0m model_id \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(model_id)\n\u001b[0;32m--> 258\u001b[0m ds \u001b[38;5;241m=\u001b[39m \u001b[43mdatasets\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43manswers_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43manswers_subset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msplit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtest\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    259\u001b[0m df \u001b[38;5;241m=\u001b[39m ds\u001b[38;5;241m.\u001b[39mto_pandas()\n\u001b[1;32m    260\u001b[0m df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcorrect\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mapply(get_correct, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.12.0/lib/python3.12/site-packages/datasets/load.py:2609\u001b[0m, in \u001b[0;36mload_dataset\u001b[0;34m(path, name, data_dir, data_files, split, cache_dir, features, download_config, download_mode, verification_mode, ignore_verifications, keep_in_memory, save_infos, revision, token, use_auth_token, task, streaming, num_proc, storage_options, trust_remote_code, **config_kwargs)\u001b[0m\n\u001b[1;32m   2606\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m builder_instance\u001b[38;5;241m.\u001b[39mas_streaming_dataset(split\u001b[38;5;241m=\u001b[39msplit)\n\u001b[1;32m   2608\u001b[0m \u001b[38;5;66;03m# Download and prepare data\u001b[39;00m\n\u001b[0;32m-> 2609\u001b[0m \u001b[43mbuilder_instance\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdownload_and_prepare\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2610\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdownload_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdownload_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2611\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdownload_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdownload_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2612\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverification_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverification_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2613\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_proc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_proc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2614\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2615\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2617\u001b[0m \u001b[38;5;66;03m# Build dataset for splits\u001b[39;00m\n\u001b[1;32m   2618\u001b[0m keep_in_memory \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   2619\u001b[0m     keep_in_memory \u001b[38;5;28;01mif\u001b[39;00m keep_in_memory \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m is_small_dataset(builder_instance\u001b[38;5;241m.\u001b[39minfo\u001b[38;5;241m.\u001b[39mdataset_size)\n\u001b[1;32m   2620\u001b[0m )\n",
      "File \u001b[0;32m~/.pyenv/versions/3.12.0/lib/python3.12/site-packages/datasets/builder.py:1027\u001b[0m, in \u001b[0;36mDatasetBuilder.download_and_prepare\u001b[0;34m(self, output_dir, download_config, download_mode, verification_mode, ignore_verifications, try_from_hf_gcs, dl_manager, base_path, use_auth_token, file_format, max_shard_size, num_proc, storage_options, **download_and_prepare_kwargs)\u001b[0m\n\u001b[1;32m   1025\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m num_proc \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1026\u001b[0m         prepare_split_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnum_proc\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m num_proc\n\u001b[0;32m-> 1027\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_download_and_prepare\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1028\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdl_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdl_manager\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1029\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverification_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverification_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1030\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mprepare_split_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1031\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mdownload_and_prepare_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1032\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1033\u001b[0m \u001b[38;5;66;03m# Sync info\u001b[39;00m\n\u001b[1;32m   1034\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minfo\u001b[38;5;241m.\u001b[39mdataset_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msum\u001b[39m(split\u001b[38;5;241m.\u001b[39mnum_bytes \u001b[38;5;28;01mfor\u001b[39;00m split \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minfo\u001b[38;5;241m.\u001b[39msplits\u001b[38;5;241m.\u001b[39mvalues())\n",
      "File \u001b[0;32m~/.pyenv/versions/3.12.0/lib/python3.12/site-packages/datasets/builder.py:1140\u001b[0m, in \u001b[0;36mDatasetBuilder._download_and_prepare\u001b[0;34m(self, dl_manager, verification_mode, **prepare_split_kwargs)\u001b[0m\n\u001b[1;32m   1137\u001b[0m     dl_manager\u001b[38;5;241m.\u001b[39mmanage_extracted_files()\n\u001b[1;32m   1139\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m verification_mode \u001b[38;5;241m==\u001b[39m VerificationMode\u001b[38;5;241m.\u001b[39mBASIC_CHECKS \u001b[38;5;129;01mor\u001b[39;00m verification_mode \u001b[38;5;241m==\u001b[39m VerificationMode\u001b[38;5;241m.\u001b[39mALL_CHECKS:\n\u001b[0;32m-> 1140\u001b[0m     \u001b[43mverify_splits\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minfo\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplits\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msplit_dict\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1142\u001b[0m \u001b[38;5;66;03m# Update the info object with the splits.\u001b[39;00m\n\u001b[1;32m   1143\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minfo\u001b[38;5;241m.\u001b[39msplits \u001b[38;5;241m=\u001b[39m split_dict\n",
      "File \u001b[0;32m~/.pyenv/versions/3.12.0/lib/python3.12/site-packages/datasets/utils/info_utils.py:101\u001b[0m, in \u001b[0;36mverify_splits\u001b[0;34m(expected_splits, recorded_splits)\u001b[0m\n\u001b[1;32m     95\u001b[0m bad_splits \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m     96\u001b[0m     {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexpected\u001b[39m\u001b[38;5;124m\"\u001b[39m: expected_splits[name], \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrecorded\u001b[39m\u001b[38;5;124m\"\u001b[39m: recorded_splits[name]}\n\u001b[1;32m     97\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m expected_splits\n\u001b[1;32m     98\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m expected_splits[name]\u001b[38;5;241m.\u001b[39mnum_examples \u001b[38;5;241m!=\u001b[39m recorded_splits[name]\u001b[38;5;241m.\u001b[39mnum_examples\n\u001b[1;32m     99\u001b[0m ]\n\u001b[1;32m    100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(bad_splits) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m--> 101\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m NonMatchingSplitsSizesError(\u001b[38;5;28mstr\u001b[39m(bad_splits))\n\u001b[1;32m    102\u001b[0m logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAll the splits matched successfully.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNonMatchingSplitsSizesError\u001b[0m: [{'expected': SplitInfo(name='test', num_bytes=4527563, num_examples=32, shard_lengths=None, dataset_name=None), 'recorded': SplitInfo(name='test', num_bytes=0, num_examples=0, shard_lengths=None, dataset_name='answers')}]"
     ]
    }
   ],
   "source": [
    "result_df = score_answers(answers_subsets)\n",
    "result_df[\"acc\"] = (result_df[\"acc\"] * 100).round(2)\n",
    "result_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "pivot_df = result_df.pivot_table(\n",
    "    index=[\"model_id\", \"source\"],\n",
    "    columns=[\"agent_action_type\"],\n",
    "    values=\"acc\",\n",
    "    fill_value=float(\"nan\"),\n",
    ").reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>agent_action_type</th>\n",
       "      <th>model_id</th>\n",
       "      <th>source</th>\n",
       "      <th>code</th>\n",
       "      <th>tool-calling</th>\n",
       "      <th>vanilla</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Qwen/Qwen2.5-72B-Instruct</td>\n",
       "      <td>GAIA</td>\n",
       "      <td>28.12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Qwen/Qwen2.5-72B-Instruct</td>\n",
       "      <td>MATH</td>\n",
       "      <td>76.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Qwen/Qwen2.5-72B-Instruct</td>\n",
       "      <td>SimpleQA</td>\n",
       "      <td>88.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Qwen/Qwen2.5-Coder-32B-Instruct</td>\n",
       "      <td>GAIA</td>\n",
       "      <td>21.88</td>\n",
       "      <td>18.75</td>\n",
       "      <td>3.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Qwen/Qwen2.5-Coder-32B-Instruct</td>\n",
       "      <td>MATH</td>\n",
       "      <td>84.00</td>\n",
       "      <td>44.00</td>\n",
       "      <td>62.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Qwen/Qwen2.5-Coder-32B-Instruct</td>\n",
       "      <td>SimpleQA</td>\n",
       "      <td>74.00</td>\n",
       "      <td>58.00</td>\n",
       "      <td>8.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>anthropic/claude-3-5-sonnet-latest</td>\n",
       "      <td>GAIA</td>\n",
       "      <td>56.25</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>anthropic/claude-3-5-sonnet-latest</td>\n",
       "      <td>MATH</td>\n",
       "      <td>82.00</td>\n",
       "      <td>54.00</td>\n",
       "      <td>50.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>anthropic/claude-3-5-sonnet-latest</td>\n",
       "      <td>SimpleQA</td>\n",
       "      <td>82.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>34.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>deepseek-ai/DeepSeek-R1</td>\n",
       "      <td>GAIA</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>deepseek-ai/DeepSeek-R1</td>\n",
       "      <td>MATH</td>\n",
       "      <td>2.00</td>\n",
       "      <td>2.00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>deepseek-ai/DeepSeek-R1</td>\n",
       "      <td>SimpleQA</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>deepseek-ai/DeepSeek-R1-Distill-Qwen-32B</td>\n",
       "      <td>GAIA</td>\n",
       "      <td>9.38</td>\n",
       "      <td>12.50</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>deepseek-ai/DeepSeek-R1-Distill-Qwen-32B</td>\n",
       "      <td>MATH</td>\n",
       "      <td>0.00</td>\n",
       "      <td>44.00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>deepseek-ai/DeepSeek-R1-Distill-Qwen-32B</td>\n",
       "      <td>SimpleQA</td>\n",
       "      <td>0.00</td>\n",
       "      <td>48.00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>gpt-4o</td>\n",
       "      <td>GAIA</td>\n",
       "      <td>34.38</td>\n",
       "      <td>15.62</td>\n",
       "      <td>3.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>gpt-4o</td>\n",
       "      <td>MATH</td>\n",
       "      <td>78.00</td>\n",
       "      <td>58.00</td>\n",
       "      <td>40.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>gpt-4o</td>\n",
       "      <td>SimpleQA</td>\n",
       "      <td>80.00</td>\n",
       "      <td>86.00</td>\n",
       "      <td>6.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>meta-llama/Llama-3.1-70B-Instruct</td>\n",
       "      <td>GAIA</td>\n",
       "      <td>0.00</td>\n",
       "      <td>18.75</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>meta-llama/Llama-3.1-70B-Instruct</td>\n",
       "      <td>MATH</td>\n",
       "      <td>46.00</td>\n",
       "      <td>16.00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>meta-llama/Llama-3.1-70B-Instruct</td>\n",
       "      <td>SimpleQA</td>\n",
       "      <td>44.00</td>\n",
       "      <td>18.00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>meta-llama/Llama-3.1-8B-Instruct</td>\n",
       "      <td>GAIA</td>\n",
       "      <td>3.12</td>\n",
       "      <td>6.25</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>meta-llama/Llama-3.1-8B-Instruct</td>\n",
       "      <td>MATH</td>\n",
       "      <td>14.00</td>\n",
       "      <td>12.00</td>\n",
       "      <td>18.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>meta-llama/Llama-3.1-8B-Instruct</td>\n",
       "      <td>SimpleQA</td>\n",
       "      <td>2.00</td>\n",
       "      <td>12.00</td>\n",
       "      <td>6.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>meta-llama/Llama-3.2-3B-Instruct</td>\n",
       "      <td>GAIA</td>\n",
       "      <td>3.12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>meta-llama/Llama-3.2-3B-Instruct</td>\n",
       "      <td>MATH</td>\n",
       "      <td>40.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>meta-llama/Llama-3.2-3B-Instruct</td>\n",
       "      <td>SimpleQA</td>\n",
       "      <td>20.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>meta-llama/Llama-3.3-70B-Instruct</td>\n",
       "      <td>GAIA</td>\n",
       "      <td>31.25</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>meta-llama/Llama-3.3-70B-Instruct</td>\n",
       "      <td>MATH</td>\n",
       "      <td>72.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>40.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>meta-llama/Llama-3.3-70B-Instruct</td>\n",
       "      <td>SimpleQA</td>\n",
       "      <td>78.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>mistralai/Mistral-Nemo-Instruct-2407</td>\n",
       "      <td>GAIA</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>mistralai/Mistral-Nemo-Instruct-2407</td>\n",
       "      <td>MATH</td>\n",
       "      <td>30.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>22.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>mistralai/Mistral-Nemo-Instruct-2407</td>\n",
       "      <td>SimpleQA</td>\n",
       "      <td>30.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>mistralai/Mistral-Small-24B-Instruct-2501</td>\n",
       "      <td>GAIA</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>mistralai/Mistral-Small-24B-Instruct-2501</td>\n",
       "      <td>MATH</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>mistralai/Mistral-Small-24B-Instruct-2501</td>\n",
       "      <td>SimpleQA</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "agent_action_type                                   model_id    source   code  \\\n",
       "0                                  Qwen/Qwen2.5-72B-Instruct      GAIA  28.12   \n",
       "1                                  Qwen/Qwen2.5-72B-Instruct      MATH  76.00   \n",
       "2                                  Qwen/Qwen2.5-72B-Instruct  SimpleQA  88.00   \n",
       "3                            Qwen/Qwen2.5-Coder-32B-Instruct      GAIA  21.88   \n",
       "4                            Qwen/Qwen2.5-Coder-32B-Instruct      MATH  84.00   \n",
       "5                            Qwen/Qwen2.5-Coder-32B-Instruct  SimpleQA  74.00   \n",
       "6                         anthropic/claude-3-5-sonnet-latest      GAIA  56.25   \n",
       "7                         anthropic/claude-3-5-sonnet-latest      MATH  82.00   \n",
       "8                         anthropic/claude-3-5-sonnet-latest  SimpleQA  82.00   \n",
       "9                                    deepseek-ai/DeepSeek-R1      GAIA   0.00   \n",
       "10                                   deepseek-ai/DeepSeek-R1      MATH   2.00   \n",
       "11                                   deepseek-ai/DeepSeek-R1  SimpleQA   0.00   \n",
       "12                  deepseek-ai/DeepSeek-R1-Distill-Qwen-32B      GAIA   9.38   \n",
       "13                  deepseek-ai/DeepSeek-R1-Distill-Qwen-32B      MATH   0.00   \n",
       "14                  deepseek-ai/DeepSeek-R1-Distill-Qwen-32B  SimpleQA   0.00   \n",
       "15                                                    gpt-4o      GAIA  34.38   \n",
       "16                                                    gpt-4o      MATH  78.00   \n",
       "17                                                    gpt-4o  SimpleQA  80.00   \n",
       "18                         meta-llama/Llama-3.1-70B-Instruct      GAIA   0.00   \n",
       "19                         meta-llama/Llama-3.1-70B-Instruct      MATH  46.00   \n",
       "20                         meta-llama/Llama-3.1-70B-Instruct  SimpleQA  44.00   \n",
       "21                          meta-llama/Llama-3.1-8B-Instruct      GAIA   3.12   \n",
       "22                          meta-llama/Llama-3.1-8B-Instruct      MATH  14.00   \n",
       "23                          meta-llama/Llama-3.1-8B-Instruct  SimpleQA   2.00   \n",
       "24                          meta-llama/Llama-3.2-3B-Instruct      GAIA   3.12   \n",
       "25                          meta-llama/Llama-3.2-3B-Instruct      MATH  40.00   \n",
       "26                          meta-llama/Llama-3.2-3B-Instruct  SimpleQA  20.00   \n",
       "27                         meta-llama/Llama-3.3-70B-Instruct      GAIA  31.25   \n",
       "28                         meta-llama/Llama-3.3-70B-Instruct      MATH  72.00   \n",
       "29                         meta-llama/Llama-3.3-70B-Instruct  SimpleQA  78.00   \n",
       "30                      mistralai/Mistral-Nemo-Instruct-2407      GAIA   0.00   \n",
       "31                      mistralai/Mistral-Nemo-Instruct-2407      MATH  30.00   \n",
       "32                      mistralai/Mistral-Nemo-Instruct-2407  SimpleQA  30.00   \n",
       "33                 mistralai/Mistral-Small-24B-Instruct-2501      GAIA   0.00   \n",
       "34                 mistralai/Mistral-Small-24B-Instruct-2501      MATH   0.00   \n",
       "35                 mistralai/Mistral-Small-24B-Instruct-2501  SimpleQA   0.00   \n",
       "\n",
       "agent_action_type  tool-calling  vanilla  \n",
       "0                           NaN     6.25  \n",
       "1                           NaN    30.00  \n",
       "2                           NaN    10.00  \n",
       "3                         18.75     3.12  \n",
       "4                         44.00    62.00  \n",
       "5                         58.00     8.00  \n",
       "6                          0.00     3.12  \n",
       "7                         54.00    50.00  \n",
       "8                          0.00    34.00  \n",
       "9                          0.00      NaN  \n",
       "10                         2.00      NaN  \n",
       "11                         0.00      NaN  \n",
       "12                        12.50      NaN  \n",
       "13                        44.00      NaN  \n",
       "14                        48.00      NaN  \n",
       "15                        15.62     3.12  \n",
       "16                        58.00    40.00  \n",
       "17                        86.00     6.00  \n",
       "18                        18.75      NaN  \n",
       "19                        16.00      NaN  \n",
       "20                        18.00      NaN  \n",
       "21                         6.25     0.00  \n",
       "22                        12.00    18.00  \n",
       "23                        12.00     6.00  \n",
       "24                          NaN     0.00  \n",
       "25                          NaN    12.00  \n",
       "26                          NaN     0.00  \n",
       "27                          NaN     3.12  \n",
       "28                          NaN    40.00  \n",
       "29                          NaN    12.00  \n",
       "30                          NaN     3.12  \n",
       "31                          NaN    22.00  \n",
       "32                          NaN     6.00  \n",
       "33                         0.00      NaN  \n",
       "34                         0.00      NaN  \n",
       "35                         0.00      NaN  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(pivot_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "Rectangle.set() got an unexpected keyword argument 'hatch_linewidth'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 45\u001b[0m\n\u001b[1;32m     42\u001b[0m     pos \u001b[38;5;241m=\u001b[39m x \u001b[38;5;241m+\u001b[39m i \u001b[38;5;241m*\u001b[39m (width \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;241m+\u001b[39m spacing)\n\u001b[1;32m     44\u001b[0m     agent_bars \u001b[38;5;241m=\u001b[39m ax\u001b[38;5;241m.\u001b[39mbar(pos, agent_scores, width, label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00msource\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m (Agent)\u001b[39m\u001b[38;5;124m\"\u001b[39m, alpha\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.8\u001b[39m)\n\u001b[0;32m---> 45\u001b[0m     vanilla_bars \u001b[38;5;241m=\u001b[39m \u001b[43max\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbar\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     46\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpos\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mwidth\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.6\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     47\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvanilla_scores\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     48\u001b[0m \u001b[43m        \u001b[49m\u001b[43mwidth\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     49\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m////\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     50\u001b[0m \u001b[43m        \u001b[49m\u001b[43malpha\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.5\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     51\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhatch_linewidth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     52\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlabel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43msource\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m (Vanilla)\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     53\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcolor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mwhite\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[43m        \u001b[49m\u001b[43medgecolor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43magent_bars\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_facecolor\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;66;03m# Customize the plot\u001b[39;00m\n\u001b[1;32m     58\u001b[0m ax\u001b[38;5;241m.\u001b[39mset_ylabel(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mScore\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.12.0/lib/python3.12/site-packages/matplotlib/__init__.py:1473\u001b[0m, in \u001b[0;36m_preprocess_data.<locals>.inner\u001b[0;34m(ax, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1470\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m   1471\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minner\u001b[39m(ax, \u001b[38;5;241m*\u001b[39margs, data\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m   1472\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1473\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1474\u001b[0m \u001b[43m            \u001b[49m\u001b[43max\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1475\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mmap\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msanitize_sequence\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1476\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m{\u001b[49m\u001b[43mk\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43msanitize_sequence\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitems\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1478\u001b[0m     bound \u001b[38;5;241m=\u001b[39m new_sig\u001b[38;5;241m.\u001b[39mbind(ax, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1479\u001b[0m     auto_label \u001b[38;5;241m=\u001b[39m (bound\u001b[38;5;241m.\u001b[39marguments\u001b[38;5;241m.\u001b[39mget(label_namer)\n\u001b[1;32m   1480\u001b[0m                   \u001b[38;5;129;01mor\u001b[39;00m bound\u001b[38;5;241m.\u001b[39mkwargs\u001b[38;5;241m.\u001b[39mget(label_namer))\n",
      "File \u001b[0;32m~/.pyenv/versions/3.12.0/lib/python3.12/site-packages/matplotlib/axes/_axes.py:2591\u001b[0m, in \u001b[0;36mAxes.bar\u001b[0;34m(self, x, height, width, bottom, align, **kwargs)\u001b[0m\n\u001b[1;32m   2582\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m l, b, w, h, c, e, lw, htch, lbl \u001b[38;5;129;01min\u001b[39;00m args:\n\u001b[1;32m   2583\u001b[0m     r \u001b[38;5;241m=\u001b[39m mpatches\u001b[38;5;241m.\u001b[39mRectangle(\n\u001b[1;32m   2584\u001b[0m         xy\u001b[38;5;241m=\u001b[39m(l, b), width\u001b[38;5;241m=\u001b[39mw, height\u001b[38;5;241m=\u001b[39mh,\n\u001b[1;32m   2585\u001b[0m         facecolor\u001b[38;5;241m=\u001b[39mc,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2589\u001b[0m         hatch\u001b[38;5;241m=\u001b[39mhtch,\n\u001b[1;32m   2590\u001b[0m         )\n\u001b[0;32m-> 2591\u001b[0m     \u001b[43mr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_internal_update\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2592\u001b[0m     r\u001b[38;5;241m.\u001b[39mget_path()\u001b[38;5;241m.\u001b[39m_interpolation_steps \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m100\u001b[39m\n\u001b[1;32m   2593\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m orientation \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvertical\u001b[39m\u001b[38;5;124m'\u001b[39m:\n",
      "File \u001b[0;32m~/.pyenv/versions/3.12.0/lib/python3.12/site-packages/matplotlib/artist.py:1216\u001b[0m, in \u001b[0;36mArtist._internal_update\u001b[0;34m(self, kwargs)\u001b[0m\n\u001b[1;32m   1209\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_internal_update\u001b[39m(\u001b[38;5;28mself\u001b[39m, kwargs):\n\u001b[1;32m   1210\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1211\u001b[0m \u001b[38;5;124;03m    Update artist properties without prenormalizing them, but generating\u001b[39;00m\n\u001b[1;32m   1212\u001b[0m \u001b[38;5;124;03m    errors as if calling `set`.\u001b[39;00m\n\u001b[1;32m   1213\u001b[0m \n\u001b[1;32m   1214\u001b[0m \u001b[38;5;124;03m    The lack of prenormalization is to maintain backcompatibility.\u001b[39;00m\n\u001b[1;32m   1215\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1216\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_update_props\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1217\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{cls.__name__}\u001b[39;49;00m\u001b[38;5;124;43m.set() got an unexpected keyword argument \u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[1;32m   1218\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{prop_name!r}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.12.0/lib/python3.12/site-packages/matplotlib/artist.py:1190\u001b[0m, in \u001b[0;36mArtist._update_props\u001b[0;34m(self, props, errfmt)\u001b[0m\n\u001b[1;32m   1188\u001b[0m             func \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mset_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mk\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m   1189\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(func):\n\u001b[0;32m-> 1190\u001b[0m                 \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\n\u001b[1;32m   1191\u001b[0m                     errfmt\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m), prop_name\u001b[38;5;241m=\u001b[39mk))\n\u001b[1;32m   1192\u001b[0m             ret\u001b[38;5;241m.\u001b[39mappend(func(v))\n\u001b[1;32m   1193\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ret:\n",
      "\u001b[0;31mAttributeError\u001b[0m: Rectangle.set() got an unexpected keyword argument 'hatch_linewidth'"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABLIAAAH0CAYAAAApJQQvAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8hTgPZAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAgwklEQVR4nO3dC5CVdf348Y9JgGiWchuwGSzMRrwAQqgNNmolahoGOF5KpVI0BScvqYh5GXVMvE7iDe+JhWNoI6OjpTWOOIiKAgHmgJrhIAallcnFy/7n+8zs/ljM+btwjsfP7us1c2Z9nnPc853lzO553uf7fJ/NmpqamgIAAAAAPuU+0+gBAAAAAMDHIWQBAAAAkIKQBQAAAEAKQhYAAAAAKQhZAAAAAKQgZAEAAACQgpAFAAAAQAqdGvGkQ4cOjXXr1kXPnj0b8fQAAAAAfIqsXLkyOnfuHM8+++ynL2StXbs23n///UY8NQAAAACfMu+99140NTX9fx/XkJDVq1ev6utjjz3WiKcHAAAA4FPkm9/85sd6nDWyAAAAAEhByAIAAAAgBSELAAAAgBSELAAAAABSELIAAAAASEHIAgAAACAFIQsAAACAFIQsAAAAAFIQsgAAAABIQcgCAAAAIAUhCwAAAIAUhCwAAAAAUhCyAAAAAEhByAIAAAAgBSELAAAAgBSELAAAAABSELIAAAAASEHIAgAAACAFIQsAAACAFIQsAAAAAFLo1OgBALkdcu2sNj1+5oThdRsLAAAA7ZsZWQAAAACkIGQBAAAAkIKQBQAAAEAKQhYAAAAAKQhZAAAAAKQgZAEAAACQgpAFAAAAQApCFgAAAAApCFkAAAAApCBkAQAAAJCCkAUAAABACkIWAAAAACkIWQAAAACkIGQBAAAAkIKQBQAAAEAKQhYAAAAAKQhZAAAAAKQgZAEAAACQgpAFAAAAQApCFgAAAAApCFkAAAAApCBkAQAAAJCCkAUAAABACkIWAAAAACkIWQAAAACkIGQBAAAAkIKQBQAAAEAKQhYAAAAAKQhZAAAAAKQgZAEAAACQgpAFAAAAQApCFgAAAAApCFkAAAAApCBkAQAAAJCCkAUAAABACkIWAAAAACkIWQAAAACkIGQBAAAAkIKQBQAAAEAKQhYAAAAAKQhZAAAAAKQgZAEAAACQgpAFAAAAQPsMWX/4wx/iq1/9aqvbKaecUt23ePHiOOyww2LgwIExevToWLhwYT3GDAAAAEAH1OaQtXTp0th3331j1qxZLbeLL7443nnnnRg3blwMHTo07rvvvhg8eHCccMIJ1X4AAAAA+MRD1ksvvRQ77rhj9OzZs+W29dZbx0MPPRRdunSJM888M/r37x+TJk2KLbfcMh5++OFNHiQAAAAAbFTI2n777T+0f/78+TFkyJDYbLPNqu3ydffdd4958+bVZqQAAAAAdGhtCllNTU3xyiuvVKcTjhgxIr71rW/FFVdcEevWrYuVK1dGr169Wj2+e/fusWLFilqPGQAAAIAOqFNbHrx8+fJYvXp1dO7cOa655pp47bXXqvWx1qxZ07J/fWW7RC4AAAAA+ERD1nbbbRdz5syJz3/+89WpgzvttFN88MEH8bOf/SyGDRv2oWhVtrt27brJgwQAAACANoWs4gtf+EKr7bKw+9q1a6tF31etWtXqvrK94emGAAAAAFD3NbKeeOKJ2GOPParTCJu98MILVdwqC70///zz1TpaRfn63HPPxcCBAzdqYAAAAACw0SFr8ODB0aVLlzj33HPj5ZdfjscffzwmT54cxx13XBxwwAHx73//Oy655JJYunRp9bUErwMPPLAtTwEAAAAAmx6yttpqq7j11lvjn//8Z4wePTomTZoUhx9+eBWyyn033XRTzJ07N0aNGhXz58+PqVOnRrdu3dryFAAAAABQmzWyvvKVr8Ttt9/+P+/bbbfd4v7772/rtwQAAACA2s7IAgAAAIBGEbIAAAAASEHIAgAAACAFIQsAAACAFIQsAAAAAFIQsgAAAABIQcgCAAAAIAUhCwAAAIAUhCwAAAAAUhCyAAAAAEhByAIAAAAgBSELAAAAgBSELAAAAABSELIAAAAASEHIAgAAACAFIQsAAACAFIQsAAAAAFIQsgAAAABIQcgCAAAAIAUhCwAAAIAUhCwAAAAAUhCyAAAAAEhByAIAAAAgBSELAAAAgBSELAAAAABSELIAAAAASEHIAgAAACAFIQsAAACAFIQsAAAAAFIQsgAAAABIQcgCAAAAIAUhCwAAAIAUhCwAAAAAUhCyAAAAAEhByAIAAAAgBSELAAAAgBSELAAAAABSELIAAAAASEHIAgAAACAFIQsAAACAFIQsAAAAAFIQsgAAAABIQcgCAAAAIAUhCwAAAIAUhCwAAAAAUhCyAAAAAEhByAIAAAAgBSELAAAAgBSELAAAAABSELIAAAAASEHIAgAAACAFIQsAAACAFIQsAAAAAFIQsgAAAABIQcgCAAAAIAUhCwAAAIAUhCwAAAAAUhCyAAAAAEhByAIAAAAgBSELAAAAgBSELAAAAABSELIAAAAASEHIAgAAACAFIQsAAACAFIQsAAAAAFIQsgAAAABIQcgCAAAAoH2HrHHjxsXZZ5/dsr148eI47LDDYuDAgTF69OhYuHBhrcYIAAAAABsXsh588MF4/PHHW7bfeeedKmwNHTo07rvvvhg8eHCccMIJ1X4AAAAAaEjIeuutt2Ly5Mmx6667tux76KGHokuXLnHmmWdG//79Y9KkSbHlllvGww8/XJNBAgAAAECbQ9Zll10WI0eOjB122KFl3/z582PIkCGx2WabVdvl6+677x7z5s2r7WgBAAAA6LDaFLJmz54dzz77bJx00kmt9q9cuTJ69erVal/37t1jxYoVtRklAAAAAB3exw5Za9eujfPPPz/OO++86Nq1a6v7Vq9eHZ07d261r2yvW7eudiMFAAAAoEP72CFrypQpscsuu8Tee+/9ofvK+lgbRquyvWHwAgAAAICN1aktVypctWpVdUXCojlcPfLII3HwwQdX962vbG94uiEAAAAA1D1k3XXXXfHee++1bF9xxRXV1zPOOCOeeeaZuPnmm6Opqala6L18fe655+LEE0/c6IEBAAAAwEaFrO22267V9pZbbll97devX7Ww+5VXXhmXXHJJHHHEETF9+vRq3awDDzzw4357AAAAAKjdVQs/ylZbbRU33XRTzJ07N0aNGhXz58+PqVOnRrdu3Wrx7QEAAADg48/I2tAvfvGLVtu77bZb3H///bUYEwAAAADUZ0YWAAAAANSbkAUAAABACkIWAAAAACkIWQAAAACkIGQBAAAAkIKQBQAAAEAKQhYAAAAAKQhZAAAAAKQgZAEAAACQgpAFAAAAQApCFgAAAAApCFkAAAAApCBkAQAAAJCCkAUAAABACkIWAAAAACkIWQAAAACkIGQBAAAAkIKQBQAAAEAKQhYAAAAAKQhZAAAAAKQgZAEAAACQgpAFAAAAQApCFgAAAAApCFkAAAAApCBkAQAAAJCCkAUAAABACkIWAAAAACkIWQAAAACkIGQBAAAAkIKQBQAAAEAKQhYAAAAAKQhZAAAAAKQgZAEAAACQgpAFAAAAQApCFgAAAAApCFkAAAAApNCp0QMAAPi4Drl2VpseP3PC8LqNBQCAT54ZWQAAAACkIGQBAAAAkIKQBQAAAEAKQhYAAAAAKQhZAAAAAKQgZAEAAACQgpAFAAAAQApCFgAAAAApCFkAAAAApCBkAQAAAJCCkAUAAABACkIWAAAAACkIWQAAAACkIGQBAAAAkIKQBQAAAEAKQhYAAAAAKQhZAAAAAKQgZAEAAACQgpAFAAAAQApCFgAAAAApCFkAAAAApCBkAQAAAJCCkAUAAABACkIWAAAAACl0avQAAAAAYH2HXDurTY+fOWF43cYCfLqYkQUAAABACkIWAAAAACkIWQAAAACkIGQBAAAA0D5D1quvvho//vGPY/DgwbHPPvvELbfc0nLfsmXLYuzYsTFo0KA46KCDYtasti3QBwAAAAA1CVkffPBBjBs3LrbZZpu4//7748ILL4wbbrghZs6cGU1NTXHyySdHjx49YsaMGTFy5MgYP358LF++vC1PAQAAAAD/U6dog1WrVsVOO+0UF1xwQWy11Vax/fbbx1577RVz586tAlaZkTV9+vTo1q1b9O/fP2bPnl1FrQkTJrTlaQAAAABg02Zk9erVK6655poqYpUZWCVgPfPMMzFs2LCYP39+DBgwoIpYzYYMGRLz5s1ry1MAAAAAQG0Xe99vv/3iqKOOqtbKGjFiRKxcubIKXevr3r17rFixYmOfAgAAAAA2PWT98pe/jBtvvDFeeOGFuPTSS2P16tXRuXPnVo8p2+vWrdvYpwAAAACAjVsja3277rpr9XXt2rVxxhlnxOjRo6uYtb4Ssbp27bqxTwEAAAAAGzcjqyz2/uijj7bat8MOO8S7774bPXv2rO7f8PEbnm4IAAAAAHUPWa+99lqMHz8+3njjjZZ9CxcujG233bZa2H3RokWxZs2alvvKYvADBw7cqIEBAAAAwEaHrHI64c477xznnHNOLF26NB5//PG4/PLL48QTT6yuXNinT5+YOHFiLFmyJKZOnRoLFiyIMWPGtOUpAAAAAGDTQ9bmm28e119/fWyxxRZx+OGHx6RJk+Loo4+OY445puW+cvXCUaNGxQMPPBDXXXdd9O3bty1PAQAAAAC1Wey9d+/eMWXKlP95X79+/WLatGlt/ZYAAAAAUNsZWQAAAADQKEIWAAAAACkIWQAAAACkIGQBAAAAkIKQBQAAAEAKQhYAAAAAKQhZAAAAAKTQqdEDaE8OuXZWmx4/c8Lwuo0FAAAAoL0xIwsAAACAFIQsAAAAAFIQsgAAAABIQcgCAAAAIAUhCwAAAIAUhCwAAAAAUhCyAAAAAEhByAIAAAAgBSELAAAAgBSELAAAAABSELIAAAAASEHIAgAAACAFIQsAAACAFIQsAAAAAFIQsgAAAABIQcgCAAAAIAUhCwAAAIAUhCwAAAAAUhCyAAAAAEhByAIAAAAgBSELAAAAgBSELAAAAABSELIAAAAASEHIAgAAACAFIQsAAACAFIQsAAAAAFIQsgAAAABIQcgCAAAAIAUhCwAAAIAUhCwAAAAAUhCyAAAAAEhByAIAAAAgBSELAAAAgBSELAAAAABSELIAAAAASEHIAgAAACAFIQsAAACAFIQsAAAAAFIQsgAAAABIQcgCAAAAIAUhCwAAAIAUhCwAAAAAUhCyAAAAAEhByAIAAAAgBSELAAAAgBSELAAAAABSELIAAAAASEHIAgAAACCFTo0eANTCIdfOatPjZ04YXrexAAAAAPVhRhYAAAAAKQhZAAAAAKQgZAEAAACQgpAFAAAAQApCFgAAAAApCFkAAAAApCBkAQAAAJCCkAUAAABACkIWAAAAAO0vZL3xxhtxyimnxLBhw2LvvfeOSy+9NNauXVvdt2zZshg7dmwMGjQoDjrooJg1a1a9xgwAAABAB/SxQ1ZTU1MVsVavXh133313XH311fGnP/0prrnmmuq+k08+OXr06BEzZsyIkSNHxvjx42P58uX1HT0AAAAAHUanj/vAl19+OebNmxdPPvlkFayKErYuu+yy+MY3vlHNyJo+fXp069Yt+vfvH7Nnz66i1oQJE+o5fgAAAAA6iI89I6tnz55xyy23tESsZm+//XbMnz8/BgwYUEWsZkOGDKnCFwAAAAB8oiFr6623rtbFavbBBx/EtGnTYs8994yVK1dGr169Wj2+e/fusWLFipoMEgAAAAA2+qqFl19+eSxevDhOPfXUat2szp07t7q/bK9bt64WYwQAAACAjQtZJWLdeeed1dcdd9wxunTp8qFoVba7du1aq3ECAAAA0MG1OWRddNFFcfvtt1cRa8SIEdW+3r17x6pVq1o9rmxveLohAAAAAHwiIWvKlCnVlQmvuuqq+M53vtOyf+DAgbFo0aJYs2ZNy765c+dW+wEAAADgEw1ZL730Ulx//fVx/PHHV1ckLAu8N9+GDRsWffr0iYkTJ8aSJUti6tSpsWDBghgzZkxNBgkAAAAAnT7uAx977LF4//3344Ybbqhu63vxxReryDVp0qQYNWpU9OvXL6677rro27dvPcYMAAAAQAf0sUPWuHHjqttHKfFq2rRptRoXAAAAAGz6VQsBAAAA4JMmZAEAAACQgpAFAAAAQApCFgAAAAApCFkAAAAApCBkAQAAAJCCkAUAAABACkIWAAAAACkIWQAAAACkIGQBAAAAkIKQBQAAAEAKQhYAAAAAKQhZAAAAAKQgZAEAAACQgpAFAAAAQApCFgAAAAApCFkAAAAApCBkAQAAAJCCkAUAAABACkIWAAAAACkIWQAAAACkIGQBAAAAkIKQBQAAAEAKQhYAAAAAKQhZAAAAAKQgZAEAAACQgpAFAAAAQApCFgAAAAApCFkAAAAApCBkAQAAAJCCkAUAAABACkIWAAAAACkIWQAAAACkIGQBAAAAkIKQBQAAAEAKQhYAAAAAKQhZAAAAAKQgZAEAAACQgpAFAAAAQApCFgAAAAApCFkAAAAApCBkAQAAAJCCkAUAAABACkIWAAAAACkIWQAAAACkIGQBAAAAkIKQBQAAAEAKQhYAAAAAKQhZAAAAAKQgZAEAAACQgpAFAAAAQApCFgAAAAApCFkAAAAApCBkAQAAAJCCkAUAAABACkIWAAAAACkIWQAAAACkIGQBAAAAkIKQBQAAAEAKQhYAAAAAKQhZAAAAAKQgZAEAAACQgpAFAAAAQApCFgAAAAApCFkAAAAApCBkAQAAANC+Q9a6devi4IMPjjlz5rTsW7ZsWYwdOzYGDRoUBx10UMyaNatW4wQAAACgg9uokLV27do47bTTYsmSJS37mpqa4uSTT44ePXrEjBkzYuTIkTF+/PhYvnx5LccLAAAAQAfVqa3/w9KlS+P000+vwtX6nnrqqWpG1vTp06Nbt27Rv3//mD17dhW1JkyYUMsxAwAAANABtXlG1tNPPx177LFH3HPPPa32z58/PwYMGFBFrGZDhgyJefPm1WakAAAAAHRobZ6RddRRR/3P/StXroxevXq12te9e/dYsWLFxo8OAAAAAGp91cLVq1dH586dW+0r22VReAAAAAD41ISsLl26fChale2uXbvW6ikAAAAA6MBqFrJ69+4dq1atarWvbG94uiEAAAAANDRkDRw4MBYtWhRr1qxp2Td37txqPwAAAAB8akLWsGHDok+fPjFx4sRYsmRJTJ06NRYsWBBjxoyp1VMAAAAA0IG1+aqFH2XzzTeP66+/PiZNmhSjRo2Kfv36xXXXXRd9+/at1VMAwKfCIdfOatPjZ04YXrexAABAR7JJIevFF19stV3i1bRp0zZ1TAAAAABQv1MLAQAAAKCehCwAAAAAUhCyAAAAAEhByAIAAAAgBSELAAAAgBSELAAAAABSELIAAAAASEHIAgAAACAFIQsAAACAFIQsAAAAAFIQsgAAAABIQcgCAAAAIAUhCwAAAIAUhCwAAAAAUhCyAAAAAEhByAIAAAAgBSELAAAAgBSELAAAAABSELIAAAAASEHIAgAAACAFIQsAAACAFIQsAAAAAFIQsgAAAABIQcgCAAAAIAUhCwAAAIAUhCwAAAAAUhCyAAAAAEhByAIAAAAgBSELAAAAgBSELAAAAABSELIAAAAASEHIAgAAACAFIQsAAACAFIQsAAAAAFIQsgAAAABIQcgCAAAAIAUhCwAAAIAUhCwAAAAAUhCyAAAAAEhByAIAAAAgBSELAAAAgBSELAAAAABSELIAAAAASEHIAgAAACAFIQsAAACAFIQsAAAAAFIQsgAAAABIoVOjBwAAAHy0Q66d1abHz5wwvG5j6Wj87AE+fczIAgAAACAFIQsAAACAFIQsAAAAAFIQsgAAAABIQcgCAAAAIAUhCwAAAIAUhCwAAAAAUhCyAAAAAEhByAIAAAAgBSELAAAAgBSELAAAAABSELIAAAAASEHIAgAAACAFIQsAAACAFIQsAAAAAFIQsgAAAABIQcgCAAAAIAUhCwAAAIAUhCwAAAAAOl7IWrt2bZxzzjkxdOjQGD58eNx22221/PYAAAAAdGCdavnNJk+eHAsXLow777wzli9fHmeddVb07ds3DjjggFo+DQAAAAAdUM1C1jvvvBP33ntv3HzzzbHzzjtXtyVLlsTdd98tZAEAAACwyTZrampq2vRvE/Hcc8/FD37wg5g3b1507ty52jdnzpw4/vjjq32f+cz/ncW46667xvvvvx99+vSJ9uSNf69p0+N7b921bmPpaPzsG8fPno7I675x/OzpiLzuG8fPvnH87KHjef3112PzzTePP//5z5/MjKyVK1fGNtts0xKxih49elTrZr311lux7bbbtuzv0qVLrFu3Ltobvzwbx8++cfzs6Yi87hvHz56OyOu+cfzsG8fPHjqeTp06tWpKH/m4Wj3h6tWrP/SEzdsbRqtnn322Vk8LAAAAQAdRs6sW/q9ZVs3bXbuq6QAAAAB8SkJW7969480334z33nuv1emGJWJtvfXWtXoaAAAAADqomoWsnXbaqTqfsSzs3mzu3LnVwu7rL/QOAAAAABujZoVpiy22iEMPPTQuuOCCWLBgQTz66KNx2223xTHHHFOrpwAAAACgA6vpVKmJEyfGzjvvHMcee2xceOGFMWHChNh///2joypXbDznnHNi6NChMXz48CrsQT288cYbccopp8SwYcNi7733jksvvbR6/UG9jRs3Ls4+++xGD4N2rKy3Wd5TfO1rX4uvf/3rcdVVV0VTU1Ojh0U7vuz3CSecELvvvnvst99+cccddzR6SLTT32sHH3xwzJkzp2XfsmXLYuzYsTFo0KA46KCDYtasWQ0dI+33tVbOoDriiCNi8ODBMWLEiLj33nsbOkba9+ut2X/+85/qOPW+++6LWqjZVQubZ2Vddtll1Y2IyZMnx8KFC+POO++M5cuXx1lnnRV9+/aNAw44oNFDox0pB3QlYpW16O6+++7417/+VQXUckpvec1BvTz44IPx+OOPx/e+971GD4V27OKLL67eEN16663x3//+N0499dTqb2l5Ew619tOf/rR6fZU32kuXLo0zzjgjtttuu/j2t7/d6KHRTpQPGk8//fRYsmRJq/dyJ598cuy4444xY8aM6syW8ePHx0MPPVS9HqFWr7WyhvXxxx8fRx55ZPziF7+IRYsWVZNRevbsGfvss09Dx0v7e72t7/LLL4+///3vUSs1DVn8n3feeaeq2zfffHM1S63cyj9qCQ1CFrX08ssvV5+sPPnkk9GjR49qXwlbJSgLWdTLW2+9VcX6sg4i1PN1Vg7qbr/99thtt92qfT/60Y9i/vz5QhY1Vz4IKn9PL7rooth+++2rW/n0ePbs2UIWNVHiaDnQ23BW6VNPPVXNyJo+fXp069Yt+vfvX73uyu+/coYL1Oq1ViJpOV447bTTqu3ye658WDRz5kwhi5q/3po9++yz1e+5EkxrxSrsdfKXv/yluoJjmbLZbMiQIdWb7w8++KChY6N9Kb8QbrnllpaI1eztt99u2Jho/0ooHTlyZOywww6NHgrtWLlozFZbbVWdNr3+6azl9GmotXKl7XJ2QZmN9e6771YfFD333HPVBY2gFp5++unYY4894p577mm1vxwfDBgwoIpY6x83rH8RLajFa615CZINOW6gHq+35tMNf/7zn8d5550XnTt3jloxI6tOyrTNbbbZptU/VgkNZcpd+YR52223bej4aD/KKYXlj1KzEkqnTZsWe+65Z0PHRftVPiUun6yUT+/KBT6gXsoMhXJa1+9+97u48cYbq7gwatSo+MlPfuKKyNRcly5dqjfaZUbWr371q3j//fer19thhx3W6KHRThx11FEfedzQq1evVvu6d+8eK1as+IRGRkd5rX3xi1+sbs3+8Y9/VEtFmPlHPV5vRXn/VkJ9WTO8loSsOlm9evWHimPzdqmSUC/l/OPFixfHb3/720YPhXaoxPjzzz+/Otgrsxeg3qfpv/rqq9XpNuUT5HKwV157ZdZMOcUQau2ll16KfffdN374wx9WS0KUqLXXXnvFd7/73UYPjQ543OCYgXpas2ZNFbDKZIvDDz+80cOhnZ5yOH369HjggQdq/r2FrDp+qrfhH5/mbQd/1DNilYsLXH311dWCoVBrU6ZMiV122aXVLECol06dOlWnO1x55ZXVzKyiXDzlN7/5jZBFXWablg+BykUsynu1sgZguSrwDTfcIGRR9+OGcsbGhscNjhmol3LxlJNOOin++te/xq9//evqAyKopbJe1rnnnlut3bzhEji1IGTVSe/evePNN9+s1skqb8SL8kly+YNUTgWDWiufGpeDuxKzyqV0oR7K9PNVq1a1rP/XHOgfeeSReP755xs8OtrjGoDlAK85YhVf+tKX4vXXX2/ouGifypWm+/Xr1yoelNMhymkRUO/jhjJzYX3lb+2GpxtCLZQPiI477rj429/+Vn0AXhZ8h1orHzyWY4MXX3yxWlu3efZpObOjXJG1rPG8KYSsOikLg5aAVRZpHDp0aMuiteXTPet6UI9ZMmXa5lVXXeWqmNTVXXfdVQX6ZldccUX1tVyiHmpt4MCB1emsr7zyShWwirIA9/phC2qlRINyKmsJ9M2neZXX2/rryUC9ftdNnTq1OtWrOaSW44ay4DvUUllLd/z48fHaa69V7+nKFTKhXoH+97//fat9Rx99dHWrxSxnRaVOyvTMQw89tFoIecGCBdWlTm+77bY45phjGj002uF6Htdff30cf/zx1RueMvOv+Qa1VgJCmbHQfNtyyy2rW/lvqLUvf/nL1eXAJ06cWF0N+IknnqgO9o488shGD412aL/99ovPfvaz1akQJZ7+8Y9/rGZjlTfdUE/lyqx9+vSpfteVtdnK77ly/DBmzJhGD412ppw+PWfOnLj44ours4Sajxk2PLUVNlWZ1LP+MUO5lX3lQhYlcm3y99/k78BHKn+MSsg69thjq8uHl8X09t9//0YPi3bmscceq66sVNbwKLf1lamcAJmVWX/l1OkSr8qHRN///veFBeric5/7XNxxxx1xySWXVAGhXGG6XCHTIsjU2+abb159KDlp0qTqSpnlgO+6666Lvn37NnpotDNlKYgyK+uEE074UEwtM7Qgi82ayipcAAAAAPAp59RCAAAAAFIQsgAAAABIQcgCAAAAIAUhCwAAAIAUhCwAAAAAUhCyAAAAAEhByAIAAAAgBSELAAAAgBSELAAAAABSELIAAAAASEHIAgAAACAy+H9MqwsvdNjZ6AAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 1500x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib.legend_handler import HandlerTuple  # Added import\n",
    "\n",
    "\n",
    "# Assuming pivot_df is your original dataframe\n",
    "models = pivot_df[\"model_id\"].unique()\n",
    "sources = pivot_df[\"source\"].unique()\n",
    "\n",
    "# Create figure and axis\n",
    "plt.style.use(\"seaborn-v0_8-white\")\n",
    "fig, ax = plt.subplots(figsize=(15, 6))\n",
    "\n",
    "# Set the width of each bar group and positions of the bars\n",
    "width = 0.15  # width of each bar\n",
    "spacing = 0.02  # space between bars within a group\n",
    "group_spacing = 0.2  # space between model groups\n",
    "\n",
    "# Calculate positions for the bars\n",
    "num_sources = len(sources)\n",
    "total_width_per_group = (width + spacing) * num_sources * 2  # *2 for agent and vanilla\n",
    "x = np.arange(len(models)) * (total_width_per_group + group_spacing)\n",
    "\n",
    "# Plot bars for each source\n",
    "for i, source in enumerate(sources):\n",
    "    source_data = pivot_df[pivot_df[\"source\"] == source]\n",
    "    agent_scores = [\n",
    "        source_data[source_data[\"model_id\"] == model][\"code\"].values[0]\n",
    "        if len(source_data[source_data[\"model_id\"] == model]) > 0\n",
    "        else np.nan\n",
    "        for model in models\n",
    "    ]\n",
    "    vanilla_scores = [\n",
    "        source_data[source_data[\"model_id\"] == model][\"vanilla\"].values[0]\n",
    "        if len(source_data[source_data[\"model_id\"] == model]) > 0\n",
    "        else np.nan\n",
    "        for model in models\n",
    "    ]\n",
    "\n",
    "    # Position calculation for each pair of bars\n",
    "    pos = x + i * (width * 2 + spacing)\n",
    "\n",
    "    agent_bars = ax.bar(pos, agent_scores, width, label=f\"{source} (Agent)\", alpha=0.8)\n",
    "    vanilla_bars = ax.bar(\n",
    "        pos + width * 0.6,\n",
    "        vanilla_scores,\n",
    "        width,\n",
    "        hatch=\"////\",\n",
    "        alpha=0.5,\n",
    "        hatch_linewidth=2,\n",
    "        label=f\"{source} (Vanilla)\",\n",
    "        color=\"white\",\n",
    "        edgecolor=agent_bars[0].get_facecolor(),\n",
    "    )\n",
    "\n",
    "# Customize the plot\n",
    "ax.set_ylabel(\"Score\")\n",
    "ax.set_title(\"Model Performance Comparison\")\n",
    "\n",
    "# Set x-axis ticks in the middle of each group\n",
    "group_centers = x + (total_width_per_group - spacing) / 2\n",
    "ax.set_xticks(group_centers)\n",
    "\n",
    "# Wrap long model names to prevent overlap\n",
    "wrapped_labels = [\"\\n\".join(model.split(\"/\")) for model in models]\n",
    "ax.set_xticklabels(wrapped_labels, rotation=0, ha=\"center\")\n",
    "\n",
    "# Modify legend to combine agent and vanilla entries\n",
    "handles, labels = ax.get_legend_handles_labels()\n",
    "unique_sources = sources\n",
    "legend_elements = [\n",
    "    (handles[i * 2], handles[i * 2 + 1], labels[i * 2].replace(\" (Agent)\", \"\")) for i in range(len(unique_sources))\n",
    "]\n",
    "custom_legend = ax.legend(\n",
    "    [(agent_handle, vanilla_handle) for agent_handle, vanilla_handle, _ in legend_elements],\n",
    "    [label for _, _, label in legend_elements],\n",
    "    handler_map={tuple: HandlerTuple(ndivide=None)},\n",
    "    bbox_to_anchor=(1.05, 1),\n",
    "    loc=\"upper left\",\n",
    ")\n",
    "\n",
    "ax.yaxis.grid(True, linestyle=\"--\", alpha=0.3)\n",
    "ax.set_ylim(bottom=0)\n",
    "plt.tight_layout()\n",
    "ax.spines[\"top\"].set_visible(False)\n",
    "ax.spines[\"right\"].set_visible(False)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'formatted_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 45\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m mathjax_table\n\u001b[1;32m     44\u001b[0m \u001b[38;5;66;03m# Usage (after running your previous data processing code):\u001b[39;00m\n\u001b[0;32m---> 45\u001b[0m mathjax_table \u001b[38;5;241m=\u001b[39m create_mathjax_table(pivot_df, \u001b[43mformatted_df\u001b[49m)\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28mprint\u001b[39m(mathjax_table)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'formatted_df' is not defined"
     ]
    }
   ],
   "source": [
    "def create_mathjax_table(pivot_df, formatted_df):\n",
    "    # Start the matrix environment with 4 columns\n",
    "    # l for left-aligned model and task, c for centered numbers\n",
    "    mathjax_table = \"\\\\begin{array}{llcc}\\n\"\n",
    "    mathjax_table += \"\\\\text{Model} & \\\\text{Task} & \\\\text{Agent} & \\\\text{Vanilla} \\\\\\\\\\n\"\n",
    "    mathjax_table += \"\\\\hline\\n\"\n",
    "\n",
    "    # Sort the DataFrame by model_id and source\n",
    "    formatted_df = formatted_df.sort_values([\"model_id\", \"source\"])\n",
    "\n",
    "    current_model = None\n",
    "    for _, row in formatted_df.iterrows():\n",
    "        model = row[\"model_id\"]\n",
    "        source = row[\"source\"]\n",
    "\n",
    "        # Add a horizontal line between different models\n",
    "        if current_model is not None and current_model != model:\n",
    "            mathjax_table += \"\\\\hline\\n\"\n",
    "\n",
    "        # Format model name\n",
    "        model_display = model.replace(\"_\", \"\\\\_\")\n",
    "        if \"Qwen\" in model or \"anthropic\" in model:\n",
    "            model_display = f\"\\\\textit{{{model_display}}}\"\n",
    "\n",
    "        # If it's the same model as previous row, use empty space\n",
    "        if current_model == model:\n",
    "            model_display = \"\\\\;\"\n",
    "\n",
    "        # Add the data row\n",
    "        mathjax_table += f\"{model_display} & {source} & {row['agent']} & {row['vanilla']} \\\\\\\\\\n\"\n",
    "\n",
    "        current_model = model\n",
    "\n",
    "    mathjax_table += \"\\\\hline\\n\"\n",
    "    mathjax_table += \"\\\\end{array}\"\n",
    "\n",
    "    return mathjax_table\n",
    "\n",
    "\n",
    "# Usage (after running your previous data processing code):\n",
    "# mathjax_table = create_mathjax_table(pivot_df, formatted_df)\n",
    "# print(mathjax_table)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test",
   "language": "python",
   "name": "test"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
